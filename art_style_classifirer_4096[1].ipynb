{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Found 42500 images belonging to 13 classes.\n",
      "Number of images found: 42500\n",
      "Number of classes found: 13\n",
      "   2/1329 [..............................] - ETA: 39:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  24/1329 [..............................] - ETA: 48:20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3182: DecompressionBombWarning: Image size (96714256 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110/1329 [========================>.....] - ETA: 6:18"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - 2277s 2s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Directory where your images are located\n",
    "dataset_dir = r\"D:\\SEM-4\\PROJECTS\\ML\\Archive\"\n",
    "\n",
    "# Initialize VGG16 model, this time including the top layers\n",
    "base_model = VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "# However, instead of using the model as is, create a new model that outputs the features from the penultimate layer\n",
    "# The penultimate layer is the one before the final classification layer, and it has 4096 features\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
    "\n",
    "# Create an instance of the ImageDataGenerator for loading images\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Create a data generator for reading images from directories\n",
    "generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  # Adjust based on your GPU memory\n",
    "    class_mode='sparse',  # 'sparse' yields integer labels\n",
    "    shuffle=False  # Important for keeping labels in order\n",
    ")\n",
    "\n",
    "# Number of images and labels\n",
    "num_images = generator.samples\n",
    "print(\"Number of images found:\", num_images)\n",
    "num_classes = generator.num_classes\n",
    "print(\"Number of classes found:\", num_classes)\n",
    "\n",
    "# Extract features\n",
    "features = model.predict(generator, steps=np.ceil(num_images/32), verbose=1)\n",
    "\n",
    "# Get the labels (ensure they are in the same order as the images)\n",
    "labels = generator.classes\n",
    "\n",
    "# Saving features and labels to .npy files\n",
    "np.save('features_4096.npy', features)\n",
    "np.save('labels_4096.npy', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 4096)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "features = np.load(r'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\features_4096.npy')\n",
    "size = np.shape(features)\n",
    "print(size)\n",
    "\n",
    "labels = np.load(r'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy')\n",
    "size1 = np.shape(labels)\n",
    "print(size1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_neighbors': 15}\n",
      "Best accuracy found:  0.5213823529411765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.38      0.45       276\n",
      "           1       0.77      0.46      0.58       646\n",
      "           2       0.39      0.66      0.49      1081\n",
      "           3       0.63      0.45      0.53       506\n",
      "           4       0.69      0.63      0.66       448\n",
      "           5       0.60      0.61      0.60       594\n",
      "           6       0.94      0.31      0.47       269\n",
      "           7       0.48      0.61      0.54      1088\n",
      "           8       0.60      0.57      0.58      1204\n",
      "           9       0.33      0.54      0.41       498\n",
      "          10       0.61      0.49      0.55      1352\n",
      "          11       0.42      0.12      0.18       318\n",
      "          12       0.88      0.65      0.75       220\n",
      "\n",
      "    accuracy                           0.53      8500\n",
      "   macro avg       0.61      0.50      0.52      8500\n",
      "weighted avg       0.57      0.53      0.53      8500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming features and labels are already loaded from the .npy files\n",
    "features = np.load('D://SEM-4//ML//CODES\\Machine-Learning//features_4096.npy')\n",
    "labels = np.load('D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy')\n",
    "\n",
    "# Reshape features for kNN\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid: number of neighbors\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# Initialize a kNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit it to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best accuracy found: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate on the test set with the best parameters\n",
    "best_knn = grid_search.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1305\n",
      "Class 1: 3035\n",
      "Class 2: 5312\n",
      "Class 3: 2607\n",
      "Class 4: 2235\n",
      "Class 5: 3115\n",
      "Class 6: 1324\n",
      "Class 7: 5373\n",
      "Class 8: 6192\n",
      "Class 9: 2521\n",
      "Class 10: 6813\n",
      "Class 11: 1510\n",
      "Class 12: 1158\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your labels if not already loaded\n",
    "labels = np.load('D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy')\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "# Printing each class with its count on a new line\n",
    "for class_label, count in class_distribution.items():\n",
    "    print(f\"Class {class_label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.59\n",
      "Precision: 0.59\n",
      "Recall: 0.59\n",
      "F1 Score: 0.58\n",
      "Confusion Matrix:\n",
      "[[ 158    6   36    5    8   16    0   38   51   20   64    2    4]\n",
      " [   6  587   11   51   63   17   14   36   66    5   61    9   10]\n",
      " [  10   14  942   13    2   28    9  106  244   73  180    7    0]\n",
      " [   1   46   24  442   30   14   19   49   60    2   47   17    9]\n",
      " [   2   58    2   24  497    5    8   21   26    2   23    5    2]\n",
      " [  17   28   85    5    3  516    4   14   84   52   89    3    1]\n",
      " [   0   23   12   32   11    6  215   22   39    0   21    6    3]\n",
      " [   9   16  112   28   12   20    6 1009   79   29  265    7    4]\n",
      " [   6   39  231   35   14   36    9   58 1306   26   61   11   30]\n",
      " [  16    8  148    5    2   28    1   39   74  302  113    1    1]\n",
      " [  24   36  150   26    4   54   10  247  179   69 1220   18    8]\n",
      " [   2   19   36   42   16   14    9  112   86    3   58   73    7]\n",
      " [   0   13    2   12    1    0    2    1   54    0    6    2  241]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 0.84\n",
      "Precision: 0.85\n",
      "Recall: 0.84\n",
      "F1 Score: 0.84\n",
      "Confusion Matrix:\n",
      "[[ 669    9   43    7    3    7    0   41   42   24   42    7    3]\n",
      " [   0 1786   18   41   30   12    3   57   63    2   72   10    5]\n",
      " [   2   12 3122   13    5   19    1   99  196   47  160    3    5]\n",
      " [   0   38   15 1609   23    7    8   46   49    1   43    4    4]\n",
      " [   4   43    8   16 1408    2    7   30   18    1   19    4    0]\n",
      " [  13   25  112    8    6 1768    1   38  100   53   85    4    1]\n",
      " [   1   14    5   26    4    1  829   16   23    1   11    0    3]\n",
      " [  16   15   96   35    8   24    4 3246   84   41  189   16    3]\n",
      " [   6   42  152   20   12   34    4   70 3848   26   87    7   22]\n",
      " [   9   13  124    7    5   25    1   48   80 1385   81    4    1]\n",
      " [   9   49  123   44   12   41    5  205  185   53 4020   15    7]\n",
      " [   6   28   29   25    7    8    3  116   84    3   57  664    3]\n",
      " [   1    7    3    4    4    0    1    2   20    0    0    3  779]]\n",
      "\n",
      "\n",
      "Training Time: 5112.33 seconds\n",
      "Prediction Time: 0.23 seconds\n",
      "\n",
      "\n",
      "XGBoost Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.58\n",
      "Precision: 0.59\n",
      "Recall: 0.58\n",
      "F1 Score: 0.58\n",
      "Confusion Matrix:\n",
      "[[ 136    0   49    3    3   15    0   44   53   15   84    3    3]\n",
      " [   2  565   17   43   48   15   12   47   72    5   93    8    9]\n",
      " [   8   11  971   14    3   30    4  102  217   73  187    7    1]\n",
      " [   0   44   27  433   16   12   11   45   84    1   67   16    4]\n",
      " [   3   67    4   21  487    8    3   22   22    0   29    8    1]\n",
      " [  11   17   86    6    1  515    1   24   95   43  100    2    0]\n",
      " [   0   33   12   28    9    5  189   26   49    0   31    7    1]\n",
      " [   6    9  134   19    5   21    5 1000   83   28  273   10    3]\n",
      " [   3   25  258   29   13   24    3   64 1289   20  106   11   17]\n",
      " [  10    7  163    4    3   38    0   37   75  289  110    2    0]\n",
      " [  17   23  161   13    7   37    3  262  190   66 1248   10    8]\n",
      " [   5   16   35   32    7   15    4  104   95    3   91   65    5]\n",
      " [   0   10    3   14    2    1    1    4   61    0    7    2  229]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      "[[ 897    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 2098    0    1    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 3681    0    0    0    0    1    0    0    2    0    0]\n",
      " [   0    0    0 1847    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1560    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 2214    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  934    0    0    0    0    0    0]\n",
      " [   0    0    1    0    0    0    0 3776    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4329    0    1    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1783    0    0    0]\n",
      " [   0    0    4    0    0    0    0    3    3    0 4758    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 1033    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  824]]\n",
      "\n",
      "\n",
      "Training Time: 625.50 seconds\n",
      "Prediction Time: 0.20 seconds\n",
      "\n",
      "\n",
      "SVM Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.64\n",
      "Precision: 0.64\n",
      "Recall: 0.64\n",
      "F1 Score: 0.63\n",
      "Confusion Matrix:\n",
      "[[ 158    6   41    5    6   12    0   47   45   26   56    4    2]\n",
      " [   3  636   16   51   42    9   10   38   50    4   60    9    8]\n",
      " [  10   14 1039    7    3   15    5   97  208   62  167    1    0]\n",
      " [   1   37   24  498   20   11   14   47   55    1   37   11    4]\n",
      " [   2   56    4   26  516    2    6   21   17    0   22    3    0]\n",
      " [  15   23   76    7    1  533    1   18   78   67   78    3    1]\n",
      " [   0   18   11   31    8    3  244   20   32    1   17    4    1]\n",
      " [  12   12  108   23    9   15    5 1095   64   23  221    7    2]\n",
      " [   3   31  212   28   14   24    4   55 1387   19   58    8   19]\n",
      " [  13    5  136    3    2   18    0   33   69  353  105    1    0]\n",
      " [  18   29  128   30    6   28    7  246  161   75 1302   12    3]\n",
      " [   4   21   32   42    9    7    9  109   85    2   63   87    7]\n",
      " [   0   14    4   12    3    0    0    2   41    0    4    0  254]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 0.82\n",
      "Precision: 0.83\n",
      "Recall: 0.82\n",
      "F1 Score: 0.82\n",
      "Confusion Matrix:\n",
      "[[ 552    8   55    9    1   11    0   73   60   30   91    6    1]\n",
      " [   2 1769   19   30   28   10    5   72   60    2   86   13    3]\n",
      " [   2    6 3118    7    4   15    0  101  184   59  182    3    3]\n",
      " [   0   29   17 1611   20    5    5   63   38    3   44   11    1]\n",
      " [   5   40   11   26 1369    0    5   42   16    2   30   14    0]\n",
      " [  19   15  145    8    2 1669    0   38   98  111  107    1    1]\n",
      " [   2   14   12   37    2    1  812   14   24    1   11    2    2]\n",
      " [  21   10  129   36    4   15    1 3209   79   43  221    8    1]\n",
      " [   1   31  182   18    2   14    1   87 3858   33   80    9   14]\n",
      " [   8   12  171    4    3   21    1   53   78 1307  121    4    0]\n",
      " [  14   32  139   26    5   27    6  309  168  108 3921    9    4]\n",
      " [  11   28   42   38    5   10    2  163   95    7   88  539    5]\n",
      " [   1   10    1    8    4    0    1    5   29    0    1    2  762]]\n",
      "\n",
      "\n",
      "Training Time: 1397.22 seconds\n",
      "Prediction Time: 858.83 seconds\n",
      "\n",
      "\n",
      "Random Forest Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.52\n",
      "Precision: 0.58\n",
      "Recall: 0.52\n",
      "F1 Score: 0.51\n",
      "Confusion Matrix:\n",
      "[[  91    2   74    3    3    6    0   41   99   20   68    0    1]\n",
      " [   1  537   20   30   67   19    0   43  128    4   82    0    5]\n",
      " [   0   18  941    8    5   15    0  105  286   34  216    0    0]\n",
      " [   0   80   32  317   24   12    2   57  147    0   84    0    5]\n",
      " [   1   68    4   23  462    7    0   36   35    1   38    0    0]\n",
      " [   5   29  117    5    2  444    0   25  115   44  115    0    0]\n",
      " [   0   49   21   27   14    3   83   47  101    0   44    0    1]\n",
      " [   2   13  167   12    3   23    0  917  116   28  312    0    3]\n",
      " [   2   53  264   26    9   30    0   69 1272   14  114    0    9]\n",
      " [   5    8  216    3    1   12    0   38  100  223  132    0    0]\n",
      " [   8   40  204   10   12   30    1  253  250   55 1179    0    3]\n",
      " [   1   17   46   32    4   12    0  124  131    1  106    2    1]\n",
      " [   0   17    2   18    7    1    0    2  104    0    9    0  174]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      "[[ 897    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 2099    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 3684    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    0 1846    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1560    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 2214    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  934    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 3777    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4330    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1783    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 4768    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 1033    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  824]]\n",
      "\n",
      "\n",
      "Training Time: 195.30 seconds\n",
      "Prediction Time: 0.65 seconds\n",
      "\n",
      "\n",
      "AdaBoost Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.29\n",
      "Precision: 0.28\n",
      "Recall: 0.29\n",
      "F1 Score: 0.27\n",
      "Confusion Matrix:\n",
      "[[  5  13 189   4  11  11   2  50  71  24  22   0   6]\n",
      " [  2 323  76  42 147  58  22  38 109   3  56   0  60]\n",
      " [  7  61 785  25  28  50  10 172 231  75 161   0  23]\n",
      " [  2  85  63 135 101  34  36  65 124   8  49   0  58]\n",
      " [  0 127  17  60 291  16  17  52  37   1  29   0  28]\n",
      " [  4 104 186  17  58 168   6  56 130  28 125   0  19]\n",
      " [  0  40  32  33  48  16  41  41  68   5  36   1  29]\n",
      " [ 11  49 340  40  48  48  11 561 125  31 323   1   8]\n",
      " [  5 117 482  61  62  74  23 139 566  69  98   2 164]\n",
      " [  4  11 381   9  18  18   9  60  95  73  51   0   9]\n",
      " [  4  98 438  31  61  81  14 553 212  45 485   2  21]\n",
      " [  4  25  98  25  33  21   9 108  83   8  47   2  14]\n",
      " [  0   8   1  11   6   8   1   1  43   2  17   1 235]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 0.29\n",
      "Precision: 0.29\n",
      "Recall: 0.29\n",
      "F1 Score: 0.27\n",
      "Confusion Matrix:\n",
      "[[  11   25  437   12   24   29    3  100  137   47   66    0    6]\n",
      " [   2  690  178   99  407  108   44  105  169    9  160    0  128]\n",
      " [  10  118 1851   29   78  129   15  409  492  174  339    0   40]\n",
      " [   9  206  133  331  253   53   85  195  322   42   97    0  121]\n",
      " [   0  320   50  138  632   61   56  113   75    4   55    1   55]\n",
      " [   8  270  483   47  130  386   15  155  302   70  305    1   42]\n",
      " [   1  107   98   68   99   38  132  115  121    8   90    1   56]\n",
      " [  14  139  799   85  121   97   40 1363  318   77  697    3   24]\n",
      " [  23  269 1070  134  125  147   55  301 1346  154  273    3  430]\n",
      " [  13   43  935   20   26   46    3  145  229  161  137    0   25]\n",
      " [  10  263 1099   64  133  208   27 1205  462  118 1124    1   54]\n",
      " [   5   65  191   59   74   45   16  235  154   15  138    5   31]\n",
      " [   1   20    4   43   21    4   14    3  105    3   25    1  580]]\n",
      "\n",
      "\n",
      "Training Time: 657.45 seconds\n",
      "Prediction Time: 1.19 seconds\n",
      "\n",
      "\n",
      "Decision Tree Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.31\n",
      "Precision: 0.31\n",
      "Recall: 0.31\n",
      "F1 Score: 0.31\n",
      "Confusion Matrix:\n",
      "[[ 54  18  54  13   9  39  11  46  61  29  60  12   2]\n",
      " [ 11 306  39  97 104  53  37  39  83  26  90  23  28]\n",
      " [ 50  31 467  58  20 101  24 190 255 134 233  49  16]\n",
      " [ 12  63  55 187  56  33  39  74  89  23  60  38  31]\n",
      " [  4  81  22  54 280  32  29  34  42  19  38  26  14]\n",
      " [ 32  50 106  25  15 281  12  67  95  71 120  19   8]\n",
      " [  9  35  33  38  25  12  75  45  46  10  33  13  16]\n",
      " [ 29  46 158  71  47  64  35 586 103  59 314  71  13]\n",
      " [ 54  95 261 102  45  95  45 125 637 103 169  63  68]\n",
      " [ 35  10 155  18   7  71   8  73  91 141  96  18  15]\n",
      " [ 50  67 249  74  46 113  49 284 177 122 731  63  20]\n",
      " [ 17  22  45  43  18  28  14  75  80  16  67  43   9]\n",
      " [  2  23  19  24  20  11   7  14  65   8  16   7 118]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      "[[ 897    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 2099    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 3684    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    0 1846    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1560    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 2214    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  934    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 3777    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4330    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1783    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 4768    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 1033    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  824]]\n",
      "\n",
      "\n",
      "Training Time: 150.20 seconds\n",
      "Prediction Time: 0.03 seconds\n",
      "\n",
      "\n",
      "Naive Bayes Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.39\n",
      "Precision: 0.44\n",
      "Recall: 0.39\n",
      "F1 Score: 0.38\n",
      "Confusion Matrix:\n",
      "[[225   9  20   1  10   9   3  21  21  62   5  15   7]\n",
      " [ 34 341  10  29 221  50  41  39  40   6  30  28  67]\n",
      " [116  19 547  25  49  69  36 159 103 328 101  37  39]\n",
      " [ 33  46  29 217 117  28  48  35  40  25  23  52  67]\n",
      " [  4  29   0  22 506   8  31  20   4  10  10  16  15]\n",
      " [ 89  32  41   2  82 323  18  27  27 157  36  11  56]\n",
      " [ 16  14  11  21  41   8 178  24  19   7  18  10  23]\n",
      " [ 91  18 117  29  27  64  43 863  28 165  84  41  26]\n",
      " [160  61 250  55  70  90  31  96 480 203  28 104 234]\n",
      " [ 70   6  91   6  13  16   6  53  27 376  35  19  20]\n",
      " [134  57 117  23  59 190  25 464  96 197 533  65  85]\n",
      " [ 41  19  23  25  27  17  16 110  28  28  21  93  29]\n",
      " [  0   4   2  11   9   2   9   1  13   3   1   3 276]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 0.40\n",
      "Precision: 0.45\n",
      "Recall: 0.40\n",
      "F1 Score: 0.40\n",
      "Confusion Matrix:\n",
      "[[ 519   20   46    9   15   25    8   44   41  113   23   26    8]\n",
      " [  57  760   22   43  514  120   81   97   77   10   85   59  174]\n",
      " [ 239   31 1304   39  119  163   71  350  236  764  207   88   73]\n",
      " [ 105  127   57  548  267   64  123  105   82   78   37  125  129]\n",
      " [  10   53    2   34 1167   15   65   58   15   16   30   48   47]\n",
      " [ 187   80  110   10  201  830   22   99   58  395   85   20  117]\n",
      " [  25   44   38   43   96   26  443   62   42   15   38   26   36]\n",
      " [ 220   45  248   75  104  150   99 2033   53  394  186  113   57]\n",
      " [ 321  135  518  123  138  189   94  244 1206  493   79  259  531]\n",
      " [ 151   22  233   18   25   35   23  136   76  901   78   29   56]\n",
      " [ 347  155  255   51  139  391   79 1090  181  495 1243  171  171]\n",
      " [  59   28   48   51   79   48   36  220   61   44   59  238   62]\n",
      " [   2    8    4   29   24    3   16    8   32    8    1   15  674]]\n",
      "\n",
      "\n",
      "Training Time: 0.90 seconds\n",
      "Prediction Time: 7.50 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "\n",
    "def load_data(features_path, labels_path):\n",
    "    \"\"\"\n",
    "    Load features and labels from given file paths.\n",
    "\n",
    "    Args:\n",
    "    features_path (str): Path to the features file.\n",
    "    labels_path (str): Path to the labels file.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Loaded features.\n",
    "    np.ndarray: Loaded labels.\n",
    "    \"\"\"\n",
    "    features = np.load(features_path)\n",
    "    labels = np.load(labels_path)\n",
    "    return features, labels\n",
    "\n",
    "def reshape_features(features):\n",
    "    \"\"\"\n",
    "    Reshape features from 4D to 2D array.\n",
    "\n",
    "    Args:\n",
    "    features (np.ndarray): Features array.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Reshaped features array.\n",
    "    \"\"\"\n",
    "    return features.reshape(features.shape[0], -1)\n",
    "\n",
    "def train_and_evaluate(classifiers, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train classifiers and evaluate their performance.\n",
    "\n",
    "    Args:\n",
    "    classifiers (dict): Dictionary of classifiers.\n",
    "    X_train (np.ndarray): Training features.\n",
    "    X_test (np.ndarray): Testing features.\n",
    "    y_train (np.ndarray): Training labels.\n",
    "    y_test (np.ndarray): Testing labels.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing performance metrics for each classifier.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        start_time = time.time()  # Start timer\n",
    "        clf.fit(X_train, y_train)  # Train classifier\n",
    "        train_time = time.time() - start_time  # Calculate training time\n",
    "        start_time = time.time()  # Start timer for prediction\n",
    "        y_pred = clf.predict(X_test)  # Predict using test set\n",
    "        predict_time = time.time() - start_time  # Calculate prediction time\n",
    "        # Calculate metrics for testing data\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        test_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        test_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        test_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        # Calculate metrics for training data\n",
    "        train_y_pred = clf.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, train_y_pred)\n",
    "        train_precision = precision_score(y_train, train_y_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train, train_y_pred, average='weighted')\n",
    "        train_f1 = f1_score(y_train, train_y_pred, average='weighted')\n",
    "        train_conf_matrix = confusion_matrix(y_train, train_y_pred)\n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"test_metrics\": {\n",
    "                \"accuracy\": test_accuracy,\n",
    "                \"precision\": test_precision,\n",
    "                \"recall\": test_recall,\n",
    "                \"f1\": test_f1,\n",
    "                \"confusion_matrix\": test_conf_matrix\n",
    "            },\n",
    "            \"train_metrics\": {\n",
    "                \"accuracy\": train_accuracy,\n",
    "                \"precision\": train_precision,\n",
    "                \"recall\": train_recall,\n",
    "                \"f1\": train_f1,\n",
    "                \"confusion_matrix\": train_conf_matrix\n",
    "            },\n",
    "            \"train_time\": train_time,\n",
    "            \"predict_time\": predict_time\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "# Paths to the features and labels files\n",
    "    features_path = 'D://SEM-4//ML//CODES//Machine-Learning//features_4096.npy'\n",
    "    labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy'\n",
    "\n",
    "    # Load features and labels\n",
    "    features, labels = load_data(features_path, labels_path)\n",
    "\n",
    "    # Reshape features\n",
    "    features = reshape_features(features)\n",
    "\n",
    "    # Splitting the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Dictionary of classifiers\n",
    "    classifiers = {\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "        \"XGBoost\": XGBClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"AdaBoost\": AdaBoostClassifier(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB()\n",
    "    }\n",
    "\n",
    "    # Train and evaluate classifiers\n",
    "    results = train_and_evaluate(classifiers, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Print results\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"{name} Performance Metrics:\")\n",
    "        print(\"Testing Metrics:\")\n",
    "        print(f\"Accuracy: {metrics['test_metrics']['accuracy']:.2f}\")\n",
    "        print(f\"Precision: {metrics['test_metrics']['precision']:.2f}\")\n",
    "        print(f\"Recall: {metrics['test_metrics']['recall']:.2f}\")\n",
    "        print(f\"F1 Score: {metrics['test_metrics']['f1']:.2f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(metrics['test_metrics']['confusion_matrix'])\n",
    "        print(\"\\n\")\n",
    "        print(\"Training Metrics:\")\n",
    "        print(f\"Accuracy: {metrics['train_metrics']['accuracy']:.2f}\")\n",
    "        print(f\"Precision: {metrics['train_metrics']['precision']:.2f}\")\n",
    "        print(f\"Recall: {metrics['train_metrics']['recall']:.2f}\")\n",
    "        print(f\"F1 Score: {metrics['train_metrics']['f1']:.2f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(metrics['train_metrics']['confusion_matrix'])\n",
    "        print(\"\\n\")\n",
    "        print(f\"Training Time: {metrics['train_time']:.2f} seconds\")\n",
    "        print(f\"Prediction Time: {metrics['predict_time']:.2f} seconds\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA to explain 99% variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components selected to explain at least 99% of the variance: 3300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Paths to the features and labels files\n",
    "features_path = 'D://SEM-4//ML//CODES//Machine-Learning//features_4096.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy'# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Applying PCA to capture 99% of the variance\n",
    "pca = PCA(0.99)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "# Saving the reduced features to a new file\n",
    "reduced_features_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced//reduced_features.npy'\n",
    "np.save(reduced_features_path, features_pca)\n",
    "\n",
    "# Optionally, save the labels if you need to keep them aligned with the reduced features for later use\n",
    "reduced_labels_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced//reduced_labels.npy'\n",
    "np.save(reduced_labels_path, labels)\n",
    "\n",
    "# Number of components selected\n",
    "n_components = pca.n_components_\n",
    "print(f\"Number of principal components selected to explain at least 99% of the variance: {n_components}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.57\n",
      "Precision: 0.58\n",
      "Recall: 0.57\n",
      "F1 Score: 0.56\n",
      "Confusion Matrix:\n",
      "[[ 134    4   55    2    7   10    0   41   66   27   59    1    2]\n",
      " [   3  577   10   51   66   18   11   36   81    4   67    8    4]\n",
      " [   4   13  943   15    1   31    8  106  264   61  179    2    1]\n",
      " [   0   53   24  435   23   13   14   45   83    1   57    8    4]\n",
      " [   1   62    2   33  492    7    6   24   22    2   21    2    1]\n",
      " [  16   33   93    7    0  480    1   29   98   47   94    2    1]\n",
      " [   0   28   14   38   14    6  188   18   44    2   36    1    1]\n",
      " [   8    9  118   25    8   20    3  991  102   26  278    6    2]\n",
      " [   4   50  235   34   20   41    5   54 1290   23   80    6   20]\n",
      " [   8   10  162    3    1   29    0   33   95  279  118    0    0]\n",
      " [  15   40  150   30   11   48    9  253  202   71 1206    4    6]\n",
      " [   3   17   35   46   14   13    7  107  102    1   78   51    3]\n",
      " [   0   20    2   13    5    3    1    1   64    1    6    0  218]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 0.96\n",
      "Precision: 0.96\n",
      "Recall: 0.96\n",
      "F1 Score: 0.96\n",
      "Confusion Matrix:\n",
      "[[ 854    0   11    0    0    0    0   13    9    1    8    1    0]\n",
      " [   0 2015    7    3    1    5    0   24   18    0   25    1    0]\n",
      " [   0    7 3548    3    0   10    0   26   38    3   49    0    0]\n",
      " [   0    3    6 1788    5    4    0   19    8    0   12    2    0]\n",
      " [   1    0    2    2 1527    0    1   12    7    2    5    1    0]\n",
      " [   0    3   32    2    0 2094    0   14   26   11   32    0    0]\n",
      " [   0    0    1    0    0    1  925    4    3    0    0    0    0]\n",
      " [   0    2   37    8    3    5    0 3644   26   10   41    1    0]\n",
      " [   0   10   39    2    3    7    0   25 4209    6   27    1    1]\n",
      " [   0    6   15    4    2    9    0   16   16 1683   31    1    0]\n",
      " [   0   10   30    6    4    9    1   58   38   12 4599    1    0]\n",
      " [   0    3    4    2    2    4    0   33   13    1   13  958    0]\n",
      " [   0    0    1    0    0    0    0    0    1    0    0    0  822]]\n",
      "\n",
      "\n",
      "Training Time: 4073.99 seconds\n",
      "Prediction Time: 0.18 seconds\n",
      "\n",
      "\n",
      "XGBoost Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.54\n",
      "Precision: 0.56\n",
      "Recall: 0.54\n",
      "F1 Score: 0.52\n",
      "Confusion Matrix:\n",
      "[[ 102    6   56    2    4    8    0   42   77   23   88    0    0]\n",
      " [   3  521   16   41   58   11    8   43  110    5  111    3    6]\n",
      " [   2   15  912    6    3   12    1  128  280   40  228    1    0]\n",
      " [   0   42   34  359   32   10   12   59  120    2   81    4    5]\n",
      " [   1   65    7   35  470    4    1   26   28    1   35    0    2]\n",
      " [  13   27   88    2    5  450    0   34  119   37  123    1    2]\n",
      " [   0   35   15   26   15    3  125   30   80    0   56    0    5]\n",
      " [   3    8  124   19    9   17    0  963  119   12  316    4    2]\n",
      " [   2   43  237   28   15   21    1   62 1290   15  124    2   22]\n",
      " [   7    6  184    0    1   18    0   50  116  207  149    0    0]\n",
      " [  10   31  167   18    9   24    7  261  236   39 1237    3    3]\n",
      " [   0   14   40   32    7    6    4  116  124    8  107   17    2]\n",
      " [   0   14    2   15    5    0    2    5   89    1   14    1  186]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      "[[ 897    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 2099    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 3684    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1847    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1560    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 2214    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  934    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 3777    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4330    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1783    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 4768    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 1033    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  824]]\n",
      "\n",
      "\n",
      "Training Time: 588.19 seconds\n",
      "Prediction Time: 0.12 seconds\n",
      "\n",
      "\n",
      "SVM Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.64\n",
      "Precision: 0.65\n",
      "Recall: 0.64\n",
      "F1 Score: 0.63\n",
      "Confusion Matrix:\n",
      "[[ 158    7   36    5    6   12    0   45   45   27   61    4    2]\n",
      " [   3  641   17   49   40    8   10   38   49    4   60    9    8]\n",
      " [  10   13 1052    6    3   13    5   94  209   61  161    1    0]\n",
      " [   1   37   24  498   20   10   14   47   57    1   38   10    3]\n",
      " [   2   56    4   26  517    2    4   21   17    0   21    5    0]\n",
      " [  16   22   74    7    1  537    1   18   80   67   75    2    1]\n",
      " [   0   21   11   29    8    3  246   18   30    1   16    5    2]\n",
      " [  11   12  103   23   10   13    5 1101   65   22  223    6    2]\n",
      " [   3   32  210   28   14   23    3   55 1395   19   57    8   15]\n",
      " [  13    5  134    3    2   17    0   34   72  353  104    1    0]\n",
      " [  18   28  129   31    5   28    7  242  162   71 1309   12    3]\n",
      " [   5   21   31   39    9    7    9  106   87    2   63   92    6]\n",
      " [   0   15    4   11    3    0    0    2   41    0    4    0  254]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 0.85\n",
      "Precision: 0.85\n",
      "Recall: 0.85\n",
      "F1 Score: 0.84\n",
      "Confusion Matrix:\n",
      "[[ 578    7   50    9    1   10    0   68   54   28   84    6    2]\n",
      " [   2 1818   16   28   25    6    4   63   47    2   74   13    1]\n",
      " [   2    6 3186    6    3   14    0   89  157   53  164    2    2]\n",
      " [   0   19   12 1643   21    3    4   59   33    1   41   11    0]\n",
      " [   5   29    8   20 1406    0    2   35   13    2   27   13    0]\n",
      " [  17   13  131    4    2 1728    0   35   89   97   98    0    0]\n",
      " [   2    9   10   30    1    1  833   13   22    1    8    2    2]\n",
      " [  19    9  114   31    5   12    1 3287   66   37  189    6    1]\n",
      " [   1   24  163   17    1   10    1   76 3921   30   66    9   11]\n",
      " [   8   12  149    3    2   20    1   46   67 1363  108    4    0]\n",
      " [  13   30  120   24    4   21    4  267  141   93 4040    8    3]\n",
      " [   9   25   37   30    5    9    2  153   83    7   80  589    4]\n",
      " [   1    8    1    7    4    0    1    5   22    0    1    1  773]]\n",
      "\n",
      "\n",
      "Training Time: 1208.35 seconds\n",
      "Prediction Time: 678.99 seconds\n",
      "\n",
      "\n",
      "Random Forest Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.34\n",
      "Precision: 0.46\n",
      "Recall: 0.34\n",
      "F1 Score: 0.30\n",
      "Confusion Matrix:\n",
      "[[  10    1   78    1    1    3    0   60  142    2  110    0    0]\n",
      " [   0  181   92   11   15   17    0   82  281    0  257    0    0]\n",
      " [   0    3  604    2    0   13    0  161  443    7  395    0    0]\n",
      " [   0   22   83   36    9    6    1   87  297    0  219    0    0]\n",
      " [   0   40   71    5  130    4    0   80  164    0  181    0    0]\n",
      " [   0    7  109    2    0  259    0   71  215    2  236    0    0]\n",
      " [   0   20   44    4    2    4   27   52  138    0   99    0    0]\n",
      " [   0    0  193    0    0   12    0  706  205    4  476    0    0]\n",
      " [   0   19  303    5    2   15    0  127 1115    2  274    0    0]\n",
      " [   0    2  226    2    0    6    0   85  167   33  217    0    0]\n",
      " [   0    9  189    4    0   10    0  252  359    8 1214    0    0]\n",
      " [   0    5   55    2    2    5    0   92  142    0  174    0    0]\n",
      " [   0    6   31    1    2    5    0   16  180    0   60    0   33]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      "[[ 897    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 2099    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 3684    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1847    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1560    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 2214    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  934    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 3777    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4330    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1783    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 4768    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 1033    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  824]]\n",
      "\n",
      "\n",
      "Training Time: 482.01 seconds\n",
      "Prediction Time: 0.64 seconds\n",
      "\n",
      "\n",
      "AdaBoost Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.31\n",
      "Precision: 0.30\n",
      "Recall: 0.31\n",
      "F1 Score: 0.30\n",
      "Confusion Matrix:\n",
      "[[ 11  16 101   1  11  14   9  44 144  18  37   0   2]\n",
      " [  4 281  26  55 203  38  34  29 139   3  92   0  32]\n",
      " [  3  47 612  36  30  64  19 145 339  59 265   2   7]\n",
      " [  3  72  37 205  98  28  35  34 170   2  39   2  35]\n",
      " [  0 190   9  54 273   9  28  26  42   2  26   0  16]\n",
      " [  5  98 166  15  37 198   5  33 145  15 169   1  14]\n",
      " [  1  40  25  51  45   8  78  24  56   2  46   1  13]\n",
      " [  2  25 196  42  44  55  27 596 157  17 425   1   9]\n",
      " [  3 126 307  92  63  92  36  61 788  37 157   1  99]\n",
      " [  4  19 284  18   6  38   6  59 123  60 116   0   5]\n",
      " [  8  87 248  28  40 131  18 423 273  34 734   4  17]\n",
      " [  1  29  33  45  35  15   9  81 114   6 102   1   6]\n",
      " [  0  23   6  21   8   8  13   6  63   0  15   0 171]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 0.31\n",
      "Precision: 0.30\n",
      "Recall: 0.31\n",
      "F1 Score: 0.30\n",
      "Confusion Matrix:\n",
      "[[  31   36  237   18   21   40    6  110  262   41   94    1    0]\n",
      " [   3  612   30  100  487   92  110   76  262    3  225    2   97]\n",
      " [   9  108 1399   63   64  189   34  345  764  128  549    3   29]\n",
      " [   7  180   76  484  236   52   95  104  428    8  101    2   74]\n",
      " [   0  367   29  136  639    8   77   64  117    2   82    0   39]\n",
      " [  11  236  398   42   91  416   30  102  327   50  475    2   34]\n",
      " [   1   99   55  134  114   17  211   47  120    2  109    1   24]\n",
      " [  10   95  466   99   73  121   44 1467  374   46  960    7   15]\n",
      " [  10  232  736  193  158  173  116  184 1853   72  388    3  212]\n",
      " [   7   55  717   11   21   96   16  165  325  109  235    1   25]\n",
      " [  23  226  611   75  107  292   49  994  587   83 1688    7   26]\n",
      " [   1   64   85   73   91   29   23  169  267    4  203    7   17]\n",
      " [   0   44   10   56   32   21   20   18  148    5   32    1  437]]\n",
      "\n",
      "\n",
      "Training Time: 1439.39 seconds\n",
      "Prediction Time: 0.94 seconds\n",
      "\n",
      "\n",
      "Decision Tree Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.28\n",
      "Precision: 0.28\n",
      "Recall: 0.28\n",
      "F1 Score: 0.28\n",
      "Confusion Matrix:\n",
      "[[ 49   9  62  17   5  32  10  43  73  37  56  12   3]\n",
      " [ 13 273  47  82  90  59  49  62  95  19  88  35  24]\n",
      " [ 63  52 425  59  22 122  26 168 257 140 225  53  16]\n",
      " [ 15  74  58 160  48  39  45  55 104  28  66  39  29]\n",
      " [  8 118  28  63 276  21  22  36  29   8  31  23  12]\n",
      " [ 30  41  95  24  15 317  17  63  86  62 113  23  15]\n",
      " [  7  38  28  34  34  12  72  33  49  17  32  22  12]\n",
      " [ 52  39 153  74  33  72  32 489 138  91 338  72  13]\n",
      " [ 58 106 250 111  54 120  36 142 574 106 187  53  65]\n",
      " [ 33  19 132  25  14  56   7  82  97 130 111  23   9]\n",
      " [ 55  87 218  69  43 111  38 339 192 112 693  62  26]\n",
      " [ 21  33  38  35  26  21  14  83  68  21  78  26  13]\n",
      " [  6  28  27  21  18  16  10   9  57  11  25   9  97]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      "[[ 897    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 2099    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 3684    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1847    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 1560    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 2214    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  934    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 3777    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 4330    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1783    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 4768    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 1033    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  824]]\n",
      "\n",
      "\n",
      "Training Time: 294.79 seconds\n",
      "Prediction Time: 0.03 seconds\n",
      "\n",
      "\n",
      "Naive Bayes Performance Metrics:\n",
      "Testing Metrics:\n",
      "Accuracy: 0.21\n",
      "Precision: 0.29\n",
      "Recall: 0.21\n",
      "F1 Score: 0.19\n",
      "Confusion Matrix:\n",
      "[[  61   10   18   15    3    5   78  145   36    6   24    4    3]\n",
      " [  10  120   49   24   23   20  239  303   54    3   59   22   10]\n",
      " [  14   49  217   38    4   11  252  738  197   22   49    8   29]\n",
      " [   9   20   45  124    8    4  216  205   41    5   42   29   12]\n",
      " [   3   31   20   10   93    2  184  247    6    3   57   12    7]\n",
      " [  17   30   25   12    9   90  102  478   77   19   15    3   24]\n",
      " [   5   13   25   20    9    2  185   63   34    0   13   20    1]\n",
      " [  20   45   83   45    5    7  172 1004  105   14   58   27   11]\n",
      " [  21   46  142   39    6   20  480  545  350   21   87   32   73]\n",
      " [  11   12   51   13    1    4   78  385   81   66   20    4   12]\n",
      " [  28   60   71   53   14   13  263 1073  192   16  212   21   29]\n",
      " [   7   10   16   19    4    1   66  253   42    0   30   27    2]\n",
      " [   2    1   28    4    3    9   65   67   33    5   16    6   95]]\n",
      "\n",
      "\n",
      "Training Metrics:\n",
      "Accuracy: 0.24\n",
      "Precision: 0.37\n",
      "Recall: 0.24\n",
      "F1 Score: 0.24\n",
      "Confusion Matrix:\n",
      "[[ 210   29   24   23    0    7  174  323   33   11   41    6   16]\n",
      " [  14  339  133   23   53   37  570  654   72    6  139   42   17]\n",
      " [  25   98  579   72    3   10  565 1695  444   30   88   12   63]\n",
      " [  18   12   92  382   17   12  532  537   37   13  108   56   31]\n",
      " [   2   55   43   20  303   11  412  574    8    4   88   22   18]\n",
      " [  33   83   71   21   12  276  300 1150  175   25   20    8   40]\n",
      " [  14   16   45   43   17    7  494  163   64    4   42   24    1]\n",
      " [  50  101  222   89   18    7  357 2384  258   39  167   54   31]\n",
      " [  40   88  364   68    6   35 1051 1303  899   34  209   62  171]\n",
      " [  22   46   43   39    5    6  227  911  160  262   30    7   25]\n",
      " [  88  122  167  103   24   19  611 2482  386   40  626   44   56]\n",
      " [   3   29    7   43    6    5  184  512   63    1   17  149   14]\n",
      " [   8    4   53   10    8   21  103  122   74    4   52    9  356]]\n",
      "\n",
      "\n",
      "Training Time: 0.74 seconds\n",
      "Prediction Time: 5.89 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "\n",
    "def load_data(features_path, labels_path):\n",
    "    \"\"\"\n",
    "    Load features and labels from given file paths.\n",
    "\n",
    "    Args:\n",
    "    features_path (str): Path to the features file.\n",
    "    labels_path (str): Path to the labels file.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Loaded features.\n",
    "    np.ndarray: Loaded labels.\n",
    "    \"\"\"\n",
    "    features = np.load(features_path)\n",
    "    labels = np.load(labels_path)\n",
    "    return features, labels\n",
    "\n",
    "def reshape_features(features):\n",
    "    \"\"\"\n",
    "    Reshape features from 4D to 2D array.\n",
    "\n",
    "    Args:\n",
    "    features (np.ndarray): Features array.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Reshaped features array.\n",
    "    \"\"\"\n",
    "    return features.reshape(features.shape[0], -1)\n",
    "\n",
    "def train_and_evaluate(classifiers, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train classifiers and evaluate their performance.\n",
    "\n",
    "    Args:\n",
    "    classifiers (dict): Dictionary of classifiers.\n",
    "    X_train (np.ndarray): Training features.\n",
    "    X_test (np.ndarray): Testing features.\n",
    "    y_train (np.ndarray): Training labels.\n",
    "    y_test (np.ndarray): Testing labels.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing performance metrics for each classifier.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        start_time = time.time()  # Start timer\n",
    "        clf.fit(X_train, y_train)  # Train classifier\n",
    "        train_time = time.time() - start_time  # Calculate training time\n",
    "        start_time = time.time()  # Start timer for prediction\n",
    "        y_pred = clf.predict(X_test)  # Predict using test set\n",
    "        predict_time = time.time() - start_time  # Calculate prediction time\n",
    "        # Calculate metrics for testing data\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        test_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        test_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        test_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        # Calculate metrics for training data\n",
    "        train_y_pred = clf.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, train_y_pred)\n",
    "        train_precision = precision_score(y_train, train_y_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train, train_y_pred, average='weighted')\n",
    "        train_f1 = f1_score(y_train, train_y_pred, average='weighted')\n",
    "        train_conf_matrix = confusion_matrix(y_train, train_y_pred)\n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"test_metrics\": {\n",
    "                \"accuracy\": test_accuracy,\n",
    "                \"precision\": test_precision,\n",
    "                \"recall\": test_recall,\n",
    "                \"f1\": test_f1,\n",
    "                \"confusion_matrix\": test_conf_matrix\n",
    "            },\n",
    "            \"train_metrics\": {\n",
    "                \"accuracy\": train_accuracy,\n",
    "                \"precision\": train_precision,\n",
    "                \"recall\": train_recall,\n",
    "                \"f1\": train_f1,\n",
    "                \"confusion_matrix\": train_conf_matrix\n",
    "            },\n",
    "            \"train_time\": train_time,\n",
    "            \"predict_time\": predict_time\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Paths to the features and labels files\n",
    "    features_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced 4096//reduced_features.npy'\n",
    "    labels_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced 4096//reduced_labels.npy'\n",
    "\n",
    "    # Load features and labels\n",
    "    features, labels = load_data(features_path, labels_path)\n",
    "\n",
    "    # Reshape features\n",
    "    features = reshape_features(features)\n",
    "\n",
    "    # Splitting the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Dictionary of classifiers\n",
    "    classifiers = {\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "        \"XGBoost\": XGBClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"AdaBoost\": AdaBoostClassifier(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Naive Bayes\": GaussianNB()\n",
    "    }\n",
    "\n",
    "    # Train and evaluate classifiers\n",
    "    results = train_and_evaluate(classifiers, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Print results\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"{name} Performance Metrics:\")\n",
    "        print(\"Testing Metrics:\")\n",
    "        print(f\"Accuracy: {metrics['test_metrics']['accuracy']:.2f}\")\n",
    "        print(f\"Precision: {metrics['test_metrics']['precision']:.2f}\")\n",
    "        print(f\"Recall: {metrics['test_metrics']['recall']:.2f}\")\n",
    "        print(f\"F1 Score: {metrics['test_metrics']['f1']:.2f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(metrics['test_metrics']['confusion_matrix'])\n",
    "        print(\"\\n\")\n",
    "        print(\"Training Metrics:\")\n",
    "        print(f\"Accuracy: {metrics['train_metrics']['accuracy']:.2f}\")\n",
    "        print(f\"Precision: {metrics['train_metrics']['precision']:.2f}\")\n",
    "        print(f\"Recall: {metrics['train_metrics']['recall']:.2f}\")\n",
    "        print(f\"F1 Score: {metrics['train_metrics']['f1']:.2f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(metrics['train_metrics']['confusion_matrix'])\n",
    "        print(\"\\n\")\n",
    "        print(f\"Training Time: {metrics['train_time']:.2f} seconds\")\n",
    "        print(f\"Prediction Time: {metrics['predict_time']:.2f} seconds\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "\n",
    "features_path = 'D://SEM-4//ML//CODES//Machine-Learning//features_4096.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy'\n",
    "\n",
    "# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Dictionary of classifiers\n",
    "classifiers = {\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Start timer for training\n",
    "    start_time_train = time.time()\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # End timer for training\n",
    "    end_time_train = time.time()\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = end_time_train - start_time_train\n",
    "    \n",
    "    # Start timer for prediction\n",
    "    start_time_pred = time.time()\n",
    "    \n",
    "    # Predict the responses for the test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # End timer for prediction\n",
    "    end_time_pred = time.time()\n",
    "    \n",
    "    # Calculate prediction time\n",
    "    prediction_time = end_time_pred - start_time_pred\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = (accuracy, precision, recall, f1, conf_matrix, training_time, prediction_time)\n",
    "\n",
    "# Print all results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name} Performance Metrics:\")\n",
    "    print(f\"Accuracy: {metrics[0]:.2f}\")\n",
    "    print(f\"Precision: {metrics[1]:.2f}\")\n",
    "    print(f\"Recall: {metrics[2]:.2f}\")\n",
    "    print(f\"F1 Score: {metrics[3]:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics[4])\n",
    "    print(f\"Training Time: {metrics[5]:.4f} seconds\")\n",
    "    print(f\"Prediction Time: {metrics[6]:.4f} seconds\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29       408\n",
      "           1       0.40      0.44      0.42       936\n",
      "           2       0.28      0.34      0.31      1628\n",
      "           3       0.31      0.30      0.31       760\n",
      "           4       0.52      0.52      0.52       675\n",
      "           5       0.45      0.46      0.45       901\n",
      "           6       0.44      0.37      0.40       390\n",
      "           7       0.37      0.39      0.38      1596\n",
      "           8       0.34      0.34      0.34      1862\n",
      "           9       0.30      0.28      0.29       738\n",
      "          10       0.38      0.34      0.36      2045\n",
      "          11       0.14      0.06      0.08       477\n",
      "          12       0.59      0.61      0.60       334\n",
      "\n",
      "    accuracy                           0.36     12750\n",
      "   macro avg       0.37      0.37      0.37     12750\n",
      "weighted avg       0.36      0.36      0.36     12750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "\n",
    "# Load features and labels\n",
    "features_path = 'D://SEM-4//ML//CODES\\Machine-Learning//Reduced 4096//reduced_features.npy'\n",
    "labels_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced 4096//reduced_labels.npy'\n",
    "\n",
    "# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Dictionary of classifiers\n",
    "classifiers = {\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Start timer for training\n",
    "    start_time_train = time.time()\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # End timer for training\n",
    "    end_time_train = time.time()\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = end_time_train - start_time_train\n",
    "    \n",
    "    # Start timer for prediction\n",
    "    start_time_pred = time.time()\n",
    "    \n",
    "    # Predict the responses for the test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # End timer for prediction\n",
    "    end_time_pred = time.time()\n",
    "    \n",
    "    # Calculate prediction time\n",
    "    prediction_time = end_time_pred - start_time_pred\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = (accuracy, precision, recall, f1, conf_matrix, training_time, prediction_time)\n",
    "\n",
    "# Print all results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name} Performance Metrics:\")\n",
    "    print(f\"Accuracy: {metrics[0]:.2f}\")\n",
    "    print(f\"Precision: {metrics[1]:.2f}\")\n",
    "    print(f\"Recall: {metrics[2]:.2f}\")\n",
    "    print(f\"F1 Score: {metrics[3]:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics[4])\n",
    "    print(f\"Training Time: {metrics[5]:.4f} seconds\")\n",
    "    print(f\"Prediction Time: {metrics[6]:.4f} seconds\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
