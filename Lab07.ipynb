{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2. Use cross-validation techniques (RandomizedSearchCV()) technique to tune the \n",
    "hyperparameters for your perceptron and MLP networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Perceptron best parameters: {'penalty': None, 'max_iter': 3000, 'eta0': 0.1}\n",
      "Perceptron training accuracy: 0.3254705882352941\n",
      "Perceptron test accuracy: 0.3115294117647059\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP best parameters: {'max_iter': 1000, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (50,), 'activation': 'relu'}\n",
      "MLP training accuracy: 0.5925294117647059\n",
      "MLP test accuracy: 0.5005882352941177\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load feature vectors and labels from files.\n",
    "    \"\"\"\n",
    "    X = np.load(r\"D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\extracted_features.npy\")\n",
    "    y = np.load(r\"D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\labels.npy\")\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def setup_search_params():\n",
    "    \"\"\"\n",
    "    Setup the hyperparameter grids for both Perceptron and MLP.\n",
    "    \"\"\"\n",
    "    param_grid_perceptron = {\n",
    "        'max_iter': [1000, 3000, 5000],\n",
    "        'eta0': [0.01, 0.1, 1.0],\n",
    "        'penalty': [None, 'l2', 'l1', 'elasticnet']\n",
    "    }\n",
    "\n",
    "    param_grid_mlp = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50,50)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'max_iter': [200, 500, 1000],\n",
    "        'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    return param_grid_perceptron, param_grid_mlp\n",
    "\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train the model and evaluate it on both training and testing sets.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load data, create models, and perform training and evaluation.\n",
    "    \"\"\"\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    param_grid_perceptron, param_grid_mlp = setup_search_params()\n",
    "\n",
    "    # Perceptron with Randomized Search CV\n",
    "    random_search_perceptron = RandomizedSearchCV(\n",
    "        Perceptron(), param_distributions=param_grid_perceptron, \n",
    "        n_iter=10, scoring='accuracy', cv=5, verbose=1, random_state=42)\n",
    "    train_accuracy_perceptron, test_accuracy_perceptron = train_and_evaluate(\n",
    "        random_search_perceptron, X_train, y_train, X_test, y_test)\n",
    "    print(\"Perceptron best parameters:\", random_search_perceptron.best_params_)\n",
    "    print(\"Perceptron training accuracy:\", train_accuracy_perceptron)\n",
    "    print(\"Perceptron test accuracy:\", test_accuracy_perceptron)\n",
    "\n",
    "    # MLP with Randomized Search CV\n",
    "    random_search_mlp = RandomizedSearchCV(\n",
    "        MLPClassifier(), param_distributions=param_grid_mlp, \n",
    "        n_iter=10, scoring='accuracy', cv=5, verbose=1, random_state=42)\n",
    "    train_accuracy_mlp, test_accuracy_mlp = train_and_evaluate(\n",
    "        random_search_mlp, X_train, y_train, X_test, y_test)\n",
    "    print(\"MLP best parameters:\", random_search_mlp.best_params_)\n",
    "    print(\"MLP training accuracy:\", train_accuracy_mlp)\n",
    "    print(\"MLP test accuracy:\", test_accuracy_mlp)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3. Tabulate your results with various other classifiers such as Support Vector Machines, Decision \n",
    "Tree, RandomForest, CatBoost, AdaBoost, XGBoost, Na√Øve-Bayes. Tabulate your results for your \n",
    "problem using different performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier       Train Accuracy    Train Precision    Train Recall    Train F1    Test Accuracy    Test Precision    Test Recall    Test F1\n",
      "-------------  ----------------  -----------------  --------------  ----------  ---------------  ----------------  -------------  ---------\n",
      "CatBoost               0.837479           0.843398        0.837479    0.837454         0.523608          0.527773       0.523608   0.516043\n",
      "XGBoost                0.996773           0.996774        0.996773    0.996773         0.506039          0.517401       0.506039   0.497544\n",
      "Random Forest          0.999966           0.999966        0.999966    0.999966         0.447686          0.472379       0.447686   0.427746\n",
      "SVM                    0.42               0.462421        0.42        0.395505         0.410275          0.440147       0.410275   0.384816\n",
      "AdaBoost               0.283597           0.270916        0.283597    0.271529         0.28102           0.266179       0.28102    0.268127\n",
      "Naive Bayes            0.277378           0.393535        0.277378    0.265006         0.266667          0.367796       0.266667   0.253962\n",
      "Decision Tree          0.999966           0.999966        0.999966    0.999966         0.264471          0.265081       0.264471   0.264692\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Function to load data\n",
    "def load_data(features_path, labels_path):\n",
    "    features = np.load(features_path)\n",
    "    labels = np.load(labels_path)\n",
    "    return features, labels\n",
    "\n",
    "# Function to reshape the feature array\n",
    "def reshape_features(features):\n",
    "    # Flatten the feature arrays from (num_samples, dim1, dim2, channels) to (num_samples, features)\n",
    "    return features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Function to train classifiers and evaluate them\n",
    "def evaluate_classifier(X_train, X_test, y_train, y_test, classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_train = classifier.predict(X_train)\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "\n",
    "    # Performance metrics for training data\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    precision_train = precision_score(y_train, y_pred_train, average='weighted')\n",
    "    recall_train = recall_score(y_train, y_pred_train, average='weighted')\n",
    "    f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "    \n",
    "    # Performance metrics for test data\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "    recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "    f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "    return (accuracy_train, precision_train, recall_train, f1_train,\n",
    "            accuracy_test, precision_test, recall_test, f1_test)\n",
    "\n",
    "def main():\n",
    "    features_path = r\"D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\extracted_features.npy\"\n",
    "    labels_path = r\"D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\labels.npy\"\n",
    "    features, labels = load_data(features_path, labels_path)\n",
    "\n",
    "    # Reshape features\n",
    "    features = reshape_features(features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    classifiers = {\n",
    "        \"SVM\": SVC(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"AdaBoost\": AdaBoostClassifier(),\n",
    "        \"XGBoost\": XGBClassifier(),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0),  # verbose=0 to keep the output clean\n",
    "        \"Naive Bayes\": GaussianNB()\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, clf in classifiers.items():\n",
    "        metrics = evaluate_classifier(X_train, X_test, y_train, y_test, clf)\n",
    "        results.append((name, *metrics))  # Corrected line\n",
    "\n",
    "    # Sorting results by test accuracy for better presentation\n",
    "    results.sort(key=lambda x: x[5], reverse=True)  # index 5 is test accuracy\n",
    "\n",
    "    headers = [\"Classifier\", \"Train Accuracy\", \"Train Precision\", \"Train Recall\", \"Train F1\",\n",
    "               \"Test Accuracy\", \"Test Precision\", \"Test Recall\", \"Test F1\"]\n",
    "    print(tabulate(results, headers=headers))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
